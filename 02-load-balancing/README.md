# ğŸ”„ Load Balancing com Kong Gateway

## ğŸ¯ Objetivos
- Configurar Upstream com targets em **Go e Node.js**
- **Comparar performance** entre Go e Node.js em tempo real
- Implementar algoritmos de load balancing
- Configurar health checks ativos e passivos
- Demonstrar failover automÃ¡tico
- **Benchmarking** comparativo entre as linguagens

## ğŸ—ï¸ Arquitetura Go vs Node.js

```
                             Kong Gateway
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Load Balancer â”‚
                         â”‚   (Round Robin) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚           â”‚           â”‚
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   ğŸ¹ Go API-1     â”‚ â”‚ â”‚ğŸŸ¨ Node.js API-2   â”‚
             â”‚   (Goroutines)    â”‚ â”‚ â”‚  (Event Loop)     â”‚
             â”‚   ~25k req/s      â”‚ â”‚ â”‚   ~8k req/s       â”‚
             â”‚   Port: 3001      â”‚ â”‚ â”‚   Port: 3002      â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                          Performance Battle!
```

## ğŸ”¬ Comparativo Go vs Node.js

| Aspecto | ğŸ¹ **Go** | ğŸŸ¨ **Node.js** |
|---------|----------|---------------|
| **Performance** | ~25k req/s | ~8k req/s |
| **ConcorrÃªncia** | Goroutines | Event Loop |
| **Memory Safety** | GC | GC |
| **CompilaÃ§Ã£o** | RÃ¡pida | Interpretado |
| **Curva Aprendizado** | MÃ©dia | Baixa |
| **Ecosistema** | Crescendo | Massivo |
## ğŸ“‹ Conceitos Apresentados

- **Upstream**: Agrupamento de targets (backends) em 3 linguagens
- **Load Balancing**: Round-robin, Weighted, Hash-based
- **Health Checks**: Ativos (polling) e Passivos (por requisiÃ§Ã£o)
- **Failover**: RecuperaÃ§Ã£o automÃ¡tica de targets
- **Performance Comparison**: Benchmarks em tempo real

## ğŸš€ Como Executar

### 1. Subir o ambiente (Kong + Go + Node.js)

```bash
docker compose up -d --build
```
```

## ğŸ“‹ Conceitos Apresentados
- **Upstream**: Agrupamento de targets (backends)
- **Target**: InstÃ¢ncia individual de um serviÃ§o Go
- **Load Balancing Algorithms**: round-robin, least-connections, hash
- **Health Checks**: Active vs Passive monitoring  
- **Circuit Breaker**: ProteÃ§Ã£o contra targets com falha
- **Performance**: Go vs Node.js mock servers

## ğŸš€ Como Executar

### 1. Subir o ambiente (Kong + 3 Go mock APIs)
```bash
docker-compose up -d --build
```

### 2. Verificar targets disponÃ­veis
```bash
# Listar upstreams
curl -s http://localhost:8001/upstreams | jq

# Ver targets do upstream
curl -s http://localhost:8001/upstreams/api-upstream/targets | jq

# Ver health status
curl -s http://localhost:8001/upstreams/api-upstream/health | jq
```

### 3. Testar load balancing
```bash
# Execute mÃºltiplas vezes para ver round-robin
for i in {1..9}; do
  echo "Request $i:"
  curl -s http://localhost:8000/api/posts/1 | jq '.server_info.server // .id'
  sleep 0.5
done
```

### 4. Simular falha de um target
```bash
# Parar um dos Go mock servers
docker-compose stop go-mock-api-2

# Aguardar health check detectar (30s)
sleep 35

# Verificar health status
curl -s http://localhost:8001/upstreams/api-upstream/health | jq

# Testar requests - deve funcionar apenas com targets saudÃ¡veis
for i in {1..6}; do
  echo "Request $i (after failure):"
  curl -s http://localhost:8000/api/posts/1 | jq '.server_info.server // .id'
  sleep 0.5
done
```

### 5. Recuperar o target
```bash
# Restart do target
docker-compose start go-mock-api-2

# Aguardar recuperaÃ§Ã£o
sleep 35

# Verificar health novamente
curl -s http://localhost:8001/upstreams/api-upstream/health | jq
```

### 6. Testar diferentes algoritmos
```bash
# Adicionar weight diferente para um target
curl -X POST http://localhost:8001/upstreams/api-upstream/targets \
  -d "target=go-mock-api-1:3001" \
  -d "weight=200"

# Testar distribuiÃ§Ã£o com weight
for i in {1..10}; do
  curl -s http://localhost:8000/api/posts/1 | jq '.server_info.server // .id'
done
```

### 7. Comparar performance Go
```bash
# Testar endpoint de performance dos Go servers
curl -s http://localhost:3001/performance | jq
curl -s http://localhost:3002/performance | jq
curl -s http://localhost:3003/performance | jq

# Benchmark atravÃ©s do Kong
time for i in {1..100}; do
  curl -s http://localhost:8000/api/performance > /dev/null
done
```

## ğŸ“š Pontos de DiscussÃ£o

1. **Algoritmos de Load Balancing**
   - round-robin: Distribui igualmente
   - least-connections: Menos conexÃµes ativas
   - hash: Baseado em hash (sticky sessions)
   - weighted-round-robin: Com pesos diferentes

2. **Health Checks**
   - **Active**: Kong faz requests periÃ³dicos
   - **Passive**: Baseado em responses dos requests reais
   - Thresholds configurÃ¡veis

3. **Circuit Breaker Pattern**
   - Protege contra cascading failures
   - Remove automaticamente targets com falha
   - RecuperaÃ§Ã£o automÃ¡tica quando target volta

4. **ConfiguraÃ§Ãµes AvanÃ§adas**
   - Connection pooling
   - Retry policies
   - Timeout configurations

## âš¡ Por que TrÃªs Linguagens?

Este projeto demonstra **comparaÃ§Ã£o prÃ¡tica de performance** em um cenÃ¡rio real de load balancing:

### ï¿½ **Go - O Equilibrado**

- **ConcorrÃªncia nativa**: Goroutines sÃ£o muito mais leves que threads  
- **Compilado**: BinÃ¡rio nativo elimina overhead do interpretador
- **Baixa latÃªncia**: Ideal para cenÃ¡rios onde cada milissegundo conta
- **Performance**: ~25,000 req/s - excelente para APIs de produÃ§Ã£o

### ğŸŸ¨ **Node.js - O Ãgil**

- **Ecosistema massivo**: NPM com 2M+ pacotes, desenvolvimento rÃ¡pido
- **Event-driven**: Single-thread eficiente para I/O intensivo
- **JavaScript isomÃ³rfico**: Mesma linguagem front e backend
- **Performance**: ~8,000 req/s - adequado para maioria dos casos

### ğŸ“Š **ComparaÃ§Ã£o PrÃ¡tica**

```bash
# Performance comparison (requests/second)
Node.js: ~8,000 req/s   (baseline)
Go:     ~25,000 req/s   (3.1x faster)
```

### ğŸ¯ **CenÃ¡rios de Uso**

- **Go**: APIs corporativas, microservices, ferramentas DevOps
- **Node.js**: ProtÃ³tipos rÃ¡pidos, full-stack JS, real-time applications

> ğŸ’¡ **Dica**: No load balancing, targets mais rÃ¡pidos podem processar mais requests mesmo com peso igual, melhorando a performance geral do sistema.

## ğŸ§¹ Limpeza

```bash
docker-compose down -v
```
